# æ¼¢å­— Chinese Radicals Learning App

A modern web application for learning Chinese characters through their radicals, components, and structural relationships. Built with SvelteKit and powered by comprehensive open-source datasets.

![License](https://img.shields.io/badge/license-MIT-blue.svg)

## âœ¨ Features

### ğŸ“š Multiple Learning Paths

- **By Radical** â€” Browse all 214 Kangxi radicals and explore characters grouped by their semantic root
- **By Level** â€” Progress through HSK-aligned difficulty levels, from beginner (Grade 1) to advanced (Grade 6)
- **By Component** â€” Discover phonetic series and common building blocks that appear across many characters

### ğŸ” Character Detail Pages

Each character page includes:
- **Pinyin & definitions** from Unihan/CC-CEDICT
- **Stroke count & frequency rank** from SUBTLEX-CH corpus
- **IDS decomposition tree** â€” visual breakdown of character structure (e.g., æƒ³ = â¿±ç›¸å¿ƒ)
- **Example words** â€” common vocabulary containing the character, sorted by frequency
- **Derived characters** â€” characters that contain this one as a component
- **Simplified â†” Traditional** cross-references

### ğŸ¤– AI Chat Assistant

- "Ask AI" button on character pages to explore etymology, mnemonics, and usage
- Streaming responses via OpenRouter API (BYOK â€” bring your own key)
- Context-aware prompts with quick-start templates

### ğŸ“ Study List with SRS

- Add characters/words to your personal study list
- SM-2 spaced repetition algorithm ready
- Data persisted in IndexedDB with localStorage fallback
- Import/export study lists as JSON

## ğŸ—ï¸ Architecture

```
chinese/
â”œâ”€â”€ parse_unihan.py         # ETL pipeline: Unihan + CEDICT + CHISE + SUBTLEX â†’ radicals.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ radicals.json       # Generated unified dataset (~23MB)
â”œâ”€â”€ sveltekit-app/          # Frontend SvelteKit application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/         # Page routes
â”‚   â”‚   â”‚   â”œâ”€â”€ +page.svelte         # Home: radical grid
â”‚   â”‚   â”‚   â”œâ”€â”€ learn/               # By level view
â”‚   â”‚   â”‚   â”œâ”€â”€ phonetic/            # By component view
â”‚   â”‚   â”‚   â”œâ”€â”€ char/[char]/         # Character detail
â”‚   â”‚   â”‚   â”œâ”€â”€ word/[word]/         # Word detail
â”‚   â”‚   â”‚   â””â”€â”€ radical/[id]/        # Radical detail
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/loader.ts       # Singleton data loader
â”‚   â”‚   â”‚   â”œâ”€â”€ stores/              # Svelte stores (chat, studyList)
â”‚   â”‚   â”‚   â”œâ”€â”€ components/          # Reusable components
â”‚   â”‚   â”‚   â””â”€â”€ utils/ids.ts         # IDS parsing utilities
â”‚   â”‚   â””â”€â”€ app.css          # Global styles
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ data/radicals.json       # Symlinked dataset
â””â”€â”€ flake.nix               # Nix development environment
```

## ğŸ“Š Data Sources

The ETL pipeline (`parse_unihan.py`) merges multiple authoritative datasets:

| Source | Data Provided |
|--------|---------------|
| **Unihan** (Unicode) | Pinyin, definitions, radical classification, simplified/traditional variants |
| **CC-CEDICT** | 120k+ word definitions, phrase examples |
| **CHISE IDS** | Ideographic Description Sequences for character decomposition |
| **SUBTLEX-CH** | Character & word frequency from 33M-word film subtitle corpus |

### Generated Dataset

The output `radicals.json` contains:
- **214 radicals** with pinyin, meaning, and associated characters
- **20,000+ characters** with full metadata
- **Words** referenced by characters with frequency data

## ğŸš€ Getting Started

### Prerequisites

- Node.js 20+ (or use the Nix flake)
- Python 3.9+ with `openpyxl` (for ETL only)

### Development

```bash
# Using Nix (recommended)
nix develop

# Navigate to the app
cd sveltekit-app

# Install dependencies
npm install

# Start dev server
npm run dev -- --port 8080
```

Visit `http://localhost:8080` to explore.

### Backend API

```bash
# Backend dev shell
nix develop .#backend

# Start backend (SQLite locally)
cd backend
uvicorn app.main:app --reload --host 127.0.0.1 --port 8100
```

See `backend/README.md` for API documentation.

### Rebuilding the Dataset

If you need to regenerate `radicals.json` from source data:

```bash
# Download source files first:
# - unihan.zip from https://www.unicode.org/Public/UCD/latest/ucd/
# - cedict.txt from https://cc-cedict.org/
# - chise-ids-master from https://gitlab.chise.org/CHISE/ids
# - SUBTLEX-CH-WF.xlsx and SUBTLEX-CH-CHR.xlsx from https://www.ugent.be/pp/experimentele-psychologie/en/research/documents/subtlexch

# Run ETL
python parse_unihan.py

# Copy to static folder
cp data/radicals.json sveltekit-app/static/data/
```

## ğŸ”§ Configuration

### OpenRouter API Key

For the AI chat feature, get an API key from [openrouter.ai/keys](https://openrouter.ai/keys):

1. Click the âš™ï¸ settings icon in the header
2. Enter your API key (starts with `sk-or-...`)
3. Keys are stored locally in your browser

## ğŸ“± Screenshots

The app features a dark-themed, modern UI with:
- Responsive grid layouts for all screen sizes
- Grade-level badges (G1-G6) with color coding
- Frequency rank indicators
- Interactive IDS decomposition trees
- Resizable AI chat panel

## ğŸ›£ï¸ Roadmap

- [ ] Spaced repetition review sessions
- [ ] Handwriting input with stroke order animation
- [ ] Audio pronunciation
- [ ] User accounts with cloud sync
- [ ] HSK vocabulary lists integration

## ğŸ“„ License

MIT License â€” feel free to use, modify, and distribute.

## ğŸ™ Acknowledgments

- [Unicode Consortium](https://unicode.org/) for Unihan database
- [CC-CEDICT](https://cc-cedict.org/) for Chinese-English dictionary
- [CHISE Project](https://www.chise.org/) for IDS decomposition data
- [SUBTLEX-CH](https://www.ugent.be/pp/experimentele-psychologie/en/research/documents/subtlexch) for frequency data
